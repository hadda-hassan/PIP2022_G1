{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoAsC4KvxGNv"
   },
   "source": [
    "# Auto encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYHvWb97xGNy"
   },
   "source": [
    "## Loading and transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVjIcQRUxGN0"
   },
   "source": [
    "We will consider the MNIST database which contains 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. in a first time, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXMazvc3xGN1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten,Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,UpSampling2D,InputLayer,ReLU,BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadMNISTAsVector(subset=10000) :\n",
    "    nb_classes=10\n",
    "    (X_train_img, y_train_real), (X_test_img, y_test_real) = mnist.load_data()\n",
    "    X_train_vect = X_train_img[:subset].reshape(subset, 784)\n",
    "    X_test_vect = X_test_img.reshape(10000, 784)\n",
    "    X_train_vect = X_train_vect.astype(\"float32\")\n",
    "    X_test_vect = X_test_vect.astype(\"float32\")\n",
    "    X_train_vect /= 255\n",
    "    X_test_vect /= 255\n",
    "    y_train_cat = to_categorical(y_train_real[:subset], nb_classes)\n",
    "    y_test_cat = to_categorical(y_test_real, nb_classes)\n",
    "    return (X_train_vect, y_train_cat), (X_test_vect, y_test_cat)\n",
    "    \n",
    "def loadMNISTAsMaxtrix(subset=10000) :\n",
    "    nb_classes=10\n",
    "    img_rows, img_cols = 28, 28\n",
    "    (X_train_img, y_train_real), (X_test_img, y_test_real) = mnist.load_data()\n",
    "    X_train_mat = X_train_img[:subset].reshape(X_train_img[:subset].shape[0], img_rows, img_cols, 1)\n",
    "    X_test_mat = X_test_img.reshape(X_test_img.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    X_train_mat = X_train_mat.astype('float32')\n",
    "    X_test_mat = X_test_mat.astype('float32')\n",
    "    X_train_mat /= 255\n",
    "    X_test_mat /= 255\n",
    "    y_train_cat = to_categorical(y_train_real[:subset], nb_classes)\n",
    "    y_test_cat = to_categorical(y_test_real, nb_classes)\n",
    "    return (X_train_mat, y_train_cat), (X_test_mat, y_test_cat)\n",
    "\n",
    "def compare(decoded_imgs,img):\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(img[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "(X_train_mat, y_train_cat), (X_test_mat, y_test_cat) =loadMNISTAsMaxtrix()\n",
    "(X_train_vect, y_train_cat), (X_test_vect, y_test_cat) =loadMNISTAsVector()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfVQyil1xGN5"
   },
   "source": [
    "We now have vectors instead of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgK2rM6QxGN7"
   },
   "source": [
    "## Multi layered auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocsyc8P_xGN8"
   },
   "outputs": [],
   "source": [
    "def getAutoEncoder(encoding_dim = 1):\n",
    "    model = Sequential()\n",
    "    #encoder\n",
    "    model.add(InputLayer(input_shape=(784,)))\n",
    "    \n",
    "    #space reduction\n",
    "    model.add(Dense(encoding_dim,activation='relu',name='featurespace'))\n",
    "   \n",
    "    #Decoder\n",
    "     \n",
    "    \n",
    "\n",
    "    model.add(Dense(784, activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',  optimizer=sgd)\n",
    "\n",
    "   \n",
    "    return model\n",
    "\n",
    "model=getAutoEncoder(encoding_dim = 1)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U__BZGx4xGN-"
   },
   "outputs": [],
   "source": [
    "(X_train_vect, _), (X_test_vect, _) =loadMNISTAsVector(subset=10000)\n",
    "model=getAutoEncoder(encoding_dim = 32)\n",
    "batch_size = 256\n",
    "epochs=20\n",
    "hist = model.fit(X_train_vect, X_train_vect,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_vect, X_test_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQZ8T0PWxGN_"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(X_test_vect)\n",
    "compare(decoded_imgs,X_test_vect )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnfXxQFixNyz"
   },
   "source": [
    "# Dimension reduction\n",
    "\n",
    "You can make a model that predict the values corresponding to the neurons inside an hidden layer by the following way :\n",
    "\n",
    "```\n",
    "layer_output = model.get_layer('featurespace').output\n",
    "latent=Model(inputs=model.input,outputs=layer_output)\n",
    "```\n",
    "# Questions\n",
    "* by using an encoding dimension of size 2, represent in 2 dimension the MNIST data with an auto encoder. Add the colors corresponding to the class. Use different activation function just before the hidden representation to see the difference\n",
    "* build an auto encode for all the dataset except the images corresponding to 5. Build the latent representation of all the data and try to detect the 5 as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISJSONdwztrv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2vyivt5xGOA"
   },
   "source": [
    "## CNN auto encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "cvajmnsbxGOA"
   },
   "outputs": [],
   "source": [
    "def getCNNAutoEncoder(encoding_dim = 1):\n",
    "    model = Sequential()\n",
    "    #encoder\n",
    "    model.add(InputLayer(input_shape=(28,28,1)))\n",
    "    model.add(Conv2D(1, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # images 14x14\n",
    "    model.add(Conv2D(1,(3, 3),  padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))# images 7x7\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())                    #32x7x7\n",
    "    \n",
    "    model.add(Dense(encoding_dim,activation='relu',name='featurespace')) #16\n",
    "   \n",
    "    \n",
    "    nb_img=1\n",
    "    model.add(Dense(nb_img*7*7,activation='relu')) #nb_imgx7x7\n",
    "    #Decoder\n",
    "    model.add(Reshape((7, 7,nb_img))) #nb_imgx7x7\n",
    "    model.add(UpSampling2D((2, 2))) #images 14x14\n",
    "    model.add(Conv2D(1, (3, 3), padding='same', activation='relu'))\n",
    "   \n",
    "    model.add(UpSampling2D((2, 2))) #images 28x28\n",
    "   \n",
    "    model.add(Conv2D(1, (3, 3),  padding='same', activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',  optimizer=Adam())\n",
    "\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZCT0eJExGOA"
   },
   "outputs": [],
   "source": [
    "model=getCNNAutoEncoder(encoding_dim = 32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdD7gyaTxGOB"
   },
   "outputs": [],
   "source": [
    "(X_train_mat, _), (X_test_mat, _) =loadMNISTAsMaxtrix()\n",
    "model=getCNNAutoEncoder(encoding_dim = 32)\n",
    "batch_size = 256\n",
    "epochs=50\n",
    "model.fit(X_train_mat, X_train_mat,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_mat, X_test_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdM9Q5ISxGOB"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(X_test_mat)\n",
    "compare(decoded_imgs,X_test_mat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQGjkwnxxGOB"
   },
   "source": [
    "#Â Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "Qd31MNAQxGOC"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.1\n",
    "x_train_noisy = X_train_mat + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train_mat.shape) \n",
    "x_test_noisy = X_test_mat + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test_mat.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFlOYd4lxGOC"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(x_test_noisy)\n",
    "compare(decoded_imgs,x_test_noisy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7y6yFfuxGOC"
   },
   "source": [
    "# Image correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RcW5RhIxGOC"
   },
   "source": [
    "## denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "9z9vvaphxGOD"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train_mat + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train_mat.shape) \n",
    "x_test_noisy = X_test_mat + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test_mat.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUpkaQWtxGOD"
   },
   "outputs": [],
   "source": [
    "model=getCNNAutoEncoder(encoding_dim = 32)\n",
    "batch_size = 256\n",
    "epochs=50\n",
    "model.fit(x_train_noisy, X_train_mat,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, X_test_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcXZX9TXxGOD"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(x_test_noisy)\n",
    "compare(decoded_imgs,x_test_noisy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "id": "kOuJgZmexGOD"
   },
   "outputs": [],
   "source": [
    "(X_train_mat, _), (X_test_mat, _) =loadMNISTAsMaxtrix()\n",
    "X_train_crop=np.copy(X_train_mat)\n",
    "X_train_crop[:,:14,:14,]=0\n",
    "X_test_crop=np.copy(X_test_mat)\n",
    "X_test_crop[:,:14,:14,]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlTUFbxOxGOD"
   },
   "outputs": [],
   "source": [
    "model=getCNNAutoEncoder(encoding_dim = 32)\n",
    "batch_size = 256\n",
    "epochs=50\n",
    "model.fit(X_train_crop, X_train_mat,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_crop, X_test_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8v4OMfwnxGOE"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(X_test_crop)\n",
    "compare(decoded_imgs,X_test_crop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDifHK1rxGOE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "auto_encoder_MNIST_moodle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
